{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE 12 MONTHS OF SALES DATA INTO ONE FILE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK IF FILE ALREADY EXISTS OR NEED TO BE DELETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE TO DELETE\n",
    "file_to_delete = r'Data/Sales_Data/sales_data_combined.csv'\n",
    "# CHECK IF EXISTS\n",
    "if os.path.exists(file_to_delete):\n",
    "    # DELETE FILE\n",
    "    os.remove(file_to_delete)\n",
    "    print(f'Deleted {file_to_delete}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ CSV'S INDIVIDUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV'S\n",
    "df1 = pd.read_csv(r'Data/Sales_Data/Sales_April_2019.csv')\n",
    "df2 = pd.read_csv(r'Data/Sales_Data/Sales_August_2019.csv')\n",
    "df3 = pd.read_csv(r'Data/Sales_Data/Sales_December_2019.csv')\n",
    "df4 = pd.read_csv(r'Data/Sales_Data/Sales_February_2019.csv')\n",
    "df5 = pd.read_csv(r'Data/Sales_Data/Sales_January_2019.csv')\n",
    "df6 = pd.read_csv(r'Data/Sales_Data/Sales_July_2019.csv')\n",
    "df7 = pd.read_csv(r'Data/Sales_Data/Sales_June_2019.csv')\n",
    "df8 = pd.read_csv(r'Data/Sales_Data/Sales_March_2019.csv')\n",
    "df9 = pd.read_csv(r'Data/Sales_Data/Sales_May_2019.csv')\n",
    "df10 = pd.read_csv(r'Data/Sales_Data/Sales_November_2019.csv')\n",
    "df11 = pd.read_csv(r'Data/Sales_Data/Sales_October_2019.csv')\n",
    "df12 = pd.read_csv(r'Data/Sales_Data/Sales_September_2019.csv')\n",
    "\n",
    "print(df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT REGISTRIES NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrames = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12]\n",
    "\n",
    "num_total_registries = sum(len(df) for df in dataFrames)\n",
    "\n",
    "print(num_total_registries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNTING NUMER OF LINES / ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #COUNTING NUMBER OF LINES\n",
    "# with open(df1,'r') as file:\n",
    "#     #COUNT LINES USING LOOP\n",
    "#     num_lines= sum(1 for line in file)\n",
    "# print(f\"The file '{df1}' has {num_lines} registries\")\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE DATAFRAMES ONE BY ONE WITH CONCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE DATAFRAMES\n",
    "combined_csv = pd.concat([df1, df2, df3, df4, df5, df6,\n",
    "                         df7, df8, df9, df10, df11, df12], ignore_index=True)\n",
    "\n",
    "# SAVE MERGED DATAFRAME\n",
    "combined_csv.to_csv(r'Data/Sales_Data/sales_data_combined.csv',\n",
    "                    index=False, encoding='utf-8-sig')\n",
    "# CHECK TOTAL REGISTRIES\n",
    "num_total_registries = len(combined_csv)\n",
    "\n",
    "print(\"Merged dataframe saved to 'sales_data_combined.csv'\")\n",
    "\n",
    "print('The combined csv has', num_total_registries, 'registros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ ALL CSV IN A DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CSV MODULE\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "# FOLDER TO READ\n",
    "folder_csv_path = r'Data/Sales_Data'\n",
    "all_csv_files = os.listdir(folder_csv_path)\n",
    "# CHECK IF READ\n",
    "print(all_csv_files)\n",
    "# FILTER NON CSV FILES IN DIRECTORY\n",
    "only_csv_files = [f for f in all_csv_files if f.endswith('.csv')]\n",
    "# CREATE A LIST TO HOLD CSV\n",
    "df_csv_list = []\n",
    "\n",
    "for csv in only_csv_files:\n",
    "    csv_path = os.path.join(folder_csv_path, csv)\n",
    "    try:\n",
    "        #read csv \n",
    "        df= pd.read_csv(csv_path)\n",
    "        df_csv_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file {csv} because of error: {e}\")\n",
    "    print(df_csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE ALL CSV IN THE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCATENATE ALL FILES\n",
    "all_csv_combined = pd.concat(df_csv_list,ignore_index=True)\n",
    "#SAVE THE NEW FILE\n",
    "all_csv_combined.to_csv(os.path.join(folder_csv_path,'sales_data_combined.csv'),index=False)\n",
    "#PRINT MERGED CSV\n",
    "print(all_csv_combined)\n",
    "#READ FIRST 5 ROWS \n",
    "all_csv_combined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = pd.read_csv(r'Data/csvNovedadesene22del01al10.csv')\n",
    "reader = csv.reader(data)\n",
    "for row in reader:\n",
    "    print(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECT TO MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"asdqwe123\",\n",
    "    database=\"practicas_sql\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"SELECT title FROM movies\")\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "for x in myresult:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE MYSQL TABLE FROM COMBINED CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT TO THE DB\n",
    "connection = mysql.connector.connect(\n",
    "    host='127.0.0.1',\n",
    "    user='root',\n",
    "    password='asdqwe123',\n",
    "    database='practicas_sql'\n",
    ")\n",
    "# CREATE A CURSOR OBJECT\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# READ THE CSV FILE\n",
    "merged_df = pd.read_csv(r'Data/Sales_Data/sales_data_combined.csv')\n",
    "# TABLE NAME\n",
    "table_name = 'sales_data_combined'\n",
    "\n",
    "# CREATE TABLE IN MYSQL\n",
    "cursor.execute(f\"CREATE TABLE {table_name} ({', '.join(\n",
    "    [f'`{col}` VARCHAR(255)' for col in merged_df.columns])})\")\n",
    "\n",
    "# INSERT DATA ROWS\n",
    "for _, row in merged_df.iterrows():\n",
    "    columns = ', '.join([f\"`{col}`\" for col in merged_df.columns])\n",
    "    values = ', '.join(['%s' for _ in merged_df.columns])\n",
    "    insert_query = f\"INSERT INTO {table_name} ({columns}) VALUES ({values})\"\n",
    "    try:\n",
    "        cursor.execute(insert_query, tuple(row))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}, Query: {insert_query}, Row: {row}\")\n",
    "\n",
    "# CONFIRM CHANGES\n",
    "connection.commit()\n",
    "# CLOSE CONNECTION\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START READING CSV FROM A CERTAIN LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path= 'Data/csvNovedadesene22del01al10.csv'\n",
    "dataFrameOne = pd.read_csv(csv_file_path,skiprows=range(4))\n",
    "print(dataFrameOne.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH A FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_row(csv_file_path, skip_rows):\n",
    "    return pd.read_csv(csv_file_path, skiprows=skip_rows)\n",
    "\n",
    "csv_file_path= 'Data/csvNovedadesene22del01al10.csv'\n",
    "skip_rows = range(4)\n",
    "\n",
    "read_csv_from_row(csv_file_path, skip_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTIPLE WITH SAME ROW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_multiple_csv_with_skiprows(csv_file_paths, skip_row):\n",
    "    \"\"\"\n",
    "    Read multiple CSV files with the option to skip the same row in each file.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_paths (list): A list of file paths to the CSV files.\n",
    "        skip_row (int): The row number to skip in each CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        list of pandas.DataFrame: A list of DataFrames containing the CSV data for each file.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    for csv_file_path in csv_file_paths:\n",
    "        dataframes.append(pd.read_csv(csv_file_path, skiprows=range(skip_row)))\n",
    "    return dataframes\n",
    "\n",
    "# Example usage\n",
    "csv_file_paths = ['Data/csvNovedadesene22del01al10.csv', 'Data/csvNovedadesene22del11al20.csv', 'Data/csvNovedadesene22del21al31.csv']\n",
    "skip_row = 4  # Skip row 5 in both files\n",
    "\n",
    "dataframes = read_multiple_csv_with_skiprows(csv_file_paths, skip_row)\n",
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"DataFrame {i + 1}:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK IF THE VALUE IN THE VARIABLE IS THE SAME AS THE CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the variable value\n",
    "value_to_compare = 'Novedad,\"Apellido\",\"Nombre\",\"Tipo Doc.\",\"Nro. Doc.\",\"Legajo\",\"Edad\",\"Justificado\",\"Regimen Estaturario\",\"Planta\",\"Planta De Revista\",\"Agrupamiento\",\"Cat. Sal.\",\"Estructura Servicio\",\"Desde\",\"Hasta\",\"E2\",\"E3\",\"E4\",\"E5\",\"E6\",\"E7\",\"E8\"'\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"Data/csvNovedadesene22del01al10.csv\"\n",
    "\n",
    "# Specify the row number you want to compare (0-indexed)\n",
    "row_number_to_compare = 0\n",
    "\n",
    "# Function to check if all values in a row match the variable value\n",
    "\n",
    "\n",
    "def row_matches_value(row, value):\n",
    "    # Iterate through each value in the row\n",
    "    for cell in row:\n",
    "        # Check if the value matches the variable value\n",
    "        if cell != value:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Open the CSV file with the appropriate encoding\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "\n",
    "# Find and compare the specific row\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        if i == row_number_to_compare:\n",
    "            # Check if all values in the row match the variable value\n",
    "            if row_matches_value(row, value_to_compare):\n",
    "                print(\"All values in row\", i, \"match the variable value:\", row)\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
